\documentclass[a4paper,pt12]{article}
\usepackage{graphicx}
\usepackage{url}
\usepackage{placeins}

\begin{document}
\author{Pascal Stammer, Mats Richter, Benjamin Henne}
\title{Final Project: A Comparison Of Siamese Oneshot Classification With Softmax Classification using Deep Neural Networks}

\maketitle

\begin{abstract}
Learning from Dataset with sparse samples for individual classes and high inbalance in the distribution of classes is a big issue in deep learning and machine learning in general. Modern deep learning architectures usally require thousands of data points per class to learn generalizing concepts. Siamese Networks are an attempt to create a classifier that is very robust towards class inbalances and (in theory) able to distinguish classes by only seeing a single sample of one of the two classes (oneshot classification). This work evaluates the classification performance of a siamese neural network by comparing the classification performance against a very similar, softmax-classification convolutional neural network. We will compare the baseline performance differences between the network on a balanced dataset and further compare the performance on highly inbalanced data. 

\end{abstract}

\section{Task description}
In most machine learning approaches a large amount of data is key to achieve good or human-level performance in classification task.
But while large data collections exists for some well-defined problems, in many real world applications the data provided for
each class is often very small and more or less unbalanced. Furthermore any additional class leads to very expensive retraining of the entire model.

To address this issue of missing training data, unbalanced data and the possibility to retrain the entire model,
a procedure called one-shot classification (Fe-Fei et. al. 2003) can be used. This must be distinguished from zero-shot
classification in which the model have no access to any sample of the target classes (Palatucci et al., 2009).

In this work we use a deep neural network proposed in Koch et. al, 2015 called siamese neural network. In order to validate the siamese neural networks
single shot-classifications performance and the ability to solve the problems of unbalanced data sets we compare the classification
performance between a simple convolutional neural network and a siamese neural network with the same convolutional network structure on
the EMNIST.

The EMNIST data set consists of around 700.000 samples of handwritten digits and letters of 62-classes and is fairly unbalanced.
This gives us a good base to evaluate the classification performance on a unbalanced data set and compare this performance to classical approaches
used in the deep learning community.

\section{Related work and similar approaches}
According to Koch et. al., 2015, one-shot classification research is fairly immature and not much discussed in the deep learning
community. The first work goes back to the early 2000's done by Li Fei-Fei et al. They were developing a variational Bayesian framework for one-shot
classification that have good generalization properties with very few examples on unseen classes if the network is trained on other classes before (Fe-Fei et al., 2003; Fei-Fei et al., 2006).



\section{Theoretical basis and used procedures}

\subsection{Siamese Neural Networks}

\section{Experiments}
The experiments are aimed to look into the differences in learning behaviour between deep neural networks and siamese deep neural networks. We therefore used two simple and very similar showcase  architectures to make this comparison as clear as possible. We used the MNIST and the quantiatively larger EMNIST datasets as our data basis for our experiments. We altered the datasets class balance and the number of classes to compare the performance of both networks in increasingly difficult situations with regards to the structure of the dataset while keeping the data itself relatively simple.  

\subsection{Network Architectures}
In order to make the performance of both networks comparable and keep the complexity of the models as simple as possible, both architectures are only diverging by it's siamnese property. We also refused to use more complex architectural features like highway connections or multiple paths like in the Inception architectures, to rule out more complex influences on the typical learning behaviour of convolutional neural networks.

\includegraphics[scale=0.3]{nets.png}

\subsubsection{Dumbnet}
This network is our baseline model for comparing and evaluating the performance of the siamese network.  It consists of 3 convolutional layer with relu activation functions, valid padding, and increasing filter size. \newline
The output of the convolutional part (from now on called stem) of the network is read out by a single dense layer with 1024 units and relu activation function and fed into a 10 way (MNIST) or 62 way (EMNIST) softmax. For optimization a Adam Optimizer with default parameters was used.

\subsubsection{Simnet}
Simnet is derived from the Dumbnet architecture. The siamese part consists of two steam, each identical to the one of dumpnet. Each stem receives a single image as input. The readout is concatenated and put into a dense layer with 1024 units with relu activation function and a single unit output with sigmoidal activation function. \newline
Simnet is trained by randomly aranging the images into pairs. The labels are created like in \cite{siamese}, non matching original labels result in 1, matching original labels result in 0. This process is repeated for each epoch of training. \newline
The loss of the network is weighted by $1:10$ (MNIST) or $1:62$ (EMNIST) in favour of matching original labels, since due to the statistical probability of two random images belonging to the same class. This implies the assumption of balanced classes, even though the EMNIST dataset is not balanced. This is intentional, since no sample or class weights are applied on the loss of Dumpnet, which implies also the assumption of balanced classes. \newline
A normal Gradient Decent optimizer was used, since Adam lead to instabilities in the learning dynamics. The default values were kept the same.

\subsection{Data and Experimental Setups}

\subsubsection{MNIST Experiments}
The MNIST dataset is one of the quasi standard datasets in machine learning and deep learning. It is a balanced dataset consisting of binary, square images with a size of 28 pixels on each side. There are ten classes resembling handwritten digits from zero to nine. The dataset is balanced and known to be very solveable for simple computer vision algorithms with little noise and no missclassifications in the ground truth. \newline
The MNIST performance serves as baseline of performance on a sovable, balanced classification problem. 

\subsubsection{EMNIST Experiments}
EMNIST is a novel extension for the MNIST dataset. We used the by-class version of the dataset with 62 classes, containing additional classes for handwritten letters (lower and capital are treated as seperate classes). The most important property of this dataset is the relatively close resemblance to MNIST by simultaniousny beeing a more complex classification problem with strong inbalances between the classes.

\section{Results}

\subsubsection{MNIST Experiments}

\subsubsection{EMNIST Experiments}

\section{Conclusion}


% Dieser Stil erzeugt Verweise mit Autorenname und Jahr
%\bibliographystyle{gerapali}
%\bibliographystyle{wmaainf}
\bibliographystyle{plain}
\addcontentsline{toc}{chapter}{Literaturverzeichnis}

% Hier die Datei (ohne .bib) angeben, in der die referenzierten
% Paper stehen
\nocite{*}
\bibliography{literatur}
\end{document}